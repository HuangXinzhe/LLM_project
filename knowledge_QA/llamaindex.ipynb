{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install llama-index\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR_OPENAI_API_KEY>'\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "## showing logs\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "## load the PDF\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from llama_index import download_loader\n",
    "\n",
    "# define loader\n",
    "UnstructuredReader = download_loader('UnstructuredReader', refresh_cache=True)\n",
    "loader = UnstructuredReader()\n",
    "\n",
    "# load the data\n",
    "documents = loader.load_data('../notebooks/documents/Apple-Financial-Report-Q1-2022.pdf',split_documents=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex索引包括\n",
    "- 列表索引\n",
    "- 矢量存储索引\n",
    "- 树索引\n",
    "- 关键字表索引\n",
    "- 图索引\n",
    "- Pandas索引\n",
    "- SQL索引\n",
    "- 文档摘要索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量存储索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex\n",
    "\n",
    "index = GPTVectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键词表索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTKeywordTableIndex\n",
    "index = GPTKeywordTableIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is net operating income?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文档摘要索引\n",
    "该索引可以为每个文档提取和索引非结构化文本摘要，从而提高了现有方法之外的检索性能。这个索引比单个文本块包含更多的信息，并且比关键字标签具有更多的语义。它还允许灵活的检索，包括LLM和基于embedding的方法。\n",
    "\n",
    "在构建期间，该索引加载文档，并使用LLM从每个文档中提取摘要。在查询期间，它根据摘要检索要查询的相关文档，方法如下：\n",
    "- 基于LLM的检索：获取文档摘要集合，并请求LLM识别相关文档+相关性得分\n",
    "- 基于embedding的检索：利用摘要嵌入相似性来检索相关文档，并对检索结果的数量施加top-k限制。\n",
    "\n",
    "注意：Document Summary Index的检索类检索任何选定文档的所有节点，而不是在节点级别返回相关块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    ResponseSynthesizer\n",
    ")\n",
    "from llama_index.indices.document_summary import GPTDocumentSummaryIndex\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "wiki_titles = [\"Toronto\", \"Seattle\", \"Chicago\", \"Boston\", \"Houston\"]\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "for title in wiki_titles:\n",
    "    response = requests.get(\n",
    "        'https://en.wikipedia.org/w/api.php',\n",
    "        params={\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'titles': title,\n",
    "            'prop': 'extracts',\n",
    "            # 'exintro': True,\n",
    "            'explaintext': True,\n",
    "        }\n",
    "    ).json()\n",
    "    page = next(iter(response['query']['pages'].values()))\n",
    "    wiki_text = page['extract']\n",
    "\n",
    "    data_path = Path('data')\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path / f\"{title}.txt\", 'w') as fp:\n",
    "        fp.write(wiki_text)\n",
    "\n",
    "# Load all wiki documents\n",
    "city_docs = []\n",
    "for wiki_title in wiki_titles:\n",
    "    docs = SimpleDirectoryReader(input_files=[f\"data/{wiki_title}.txt\"]).load_data()\n",
    "    docs[0].doc_id = wiki_title\n",
    "    city_docs.extend(docs)\n",
    "\n",
    "# # LLM Predictor (gpt-3.5-turbo)\n",
    "llm_predictor_chatgpt = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor_chatgpt, chunk_size_limit=1024)\n",
    "\n",
    "# default mode of building the index\n",
    "response_synthesizer = ResponseSynthesizer.from_args(response_mode=\"tree_summarize\", use_async=True)\n",
    "doc_summary_index = GPTDocumentSummaryIndex.from_documents(\n",
    "    city_docs, \n",
    "    service_context=service_context,\n",
    "    response_synthesizer=response_synthesizer\n",
    ")\n",
    "\n",
    "doc_summary_index.get_document_summary(\"Boston\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
