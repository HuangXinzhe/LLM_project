{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoN：腾讯提出笔记链（CHAIN-OF-NOTE）来提高检索增强模型（RAG）的透明度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "论文地址：https://arxiv.org/pdf/2311.09210.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检索增强语言模型（RALM）已成为自然语言处理中一种强大的新范式。通过将大型预训练语言模型与外部知识检索相结合，RALM可以减少事实错误和幻觉，同时注入最新知识。然而，目前的RALM面临以下几个关键挑战：\n",
    "\n",
    "    - 噪声检索（Noisy retrieval）：不相关的检索文档可能会误导模型并导致错误的响应；\n",
    "    - 未知鲁棒性（Unknown robustness）：RALM很难确定他们是否有足够的知识来回答问题，当缺乏信息时，应该默认为“未知”；\n",
    "    - 缺乏透明度（Lack of transparency）：目前尚不清楚RALM是如何利用检索到的信息来生成回应的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、笔记链概述\n",
    "\n",
    "笔记链的关键思想是通过对检索到的每个文档进行总结和评估，让模型生成阅读笔记，然后再生成最终的回应。此记录过程可以增强模型的以下能力：\n",
    "\n",
    "- 评估检索到文档的相关性\n",
    "\n",
    "- 识别可靠信息与误导信息\n",
    "\n",
    "- 过滤掉无关或不可信的内容\n",
    "\n",
    "- 认识到知识差距并回应“未知”\n",
    "\n",
    "具体而言，给定一个问题和k个检索到的文档，“笔记链”会进行如下操作：\n",
    "\n",
    "- 笔记生成：为每个文档创建1个阅读笔记，然后分析其相关性；\n",
    "\n",
    "- 综合：整合笔记中的见解来确定最终回应。\n",
    "\n",
    "这种方法反映了人类的推理——将问题分解为更小的步骤。笔记为模型的思维过程提供了透明度，并提高了其噪声和未知稳健性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、阅读笔记的类型\n",
    "\n",
    "笔记链生成的笔记可分为三类：\n",
    "- 相关（Relevant）：文档可以直接回答问题，最终的回复只来自该文档；\n",
    "- 无关但有用的上下文（Irrelevant but useful context）：文档没有回答问题，但提供了有用的背景。该模型将其知识与上下文相结合可以推断出答案；\n",
    "- 无关（Irrelevant）：文档是无关的，模型缺乏知识来回答。默认响应为“未知”。\n",
    "\n",
    "该系统允许模型在直接检索信息、进行推断和承认其局限性之间取得平衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、训练模型\n",
    "\n",
    "为了训练一个模型来生成阅读笔记，腾讯团队执行如下步骤：\n",
    "\n",
    "- 使用ChatGPT为不同类型的笔记生成10K的训练数据；\n",
    "\n",
    "- 使用这些数据对LLaMa-2模型进行微调，以增强模型记笔记的能力；\n",
    "\n",
    "- 使用加权损失函数策略，将训练重点放在最终答案的准确性上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "四、实验结果分析\n",
    "\n",
    "在几个QA数据集的实验表明：\n",
    "\n",
    "- 提高了QA性能： 从上表2可以看出，当使用检索到的文档时，Chain of Note的平均得分比标准RALM高+1.97 EM；\n",
    "\n",
    "- 增强了噪声鲁棒性：从上表3可以看出，在给定不相关的检索文档的情况下，与标准RALM相比，Chain of Note将EM得分提高了+7.9；\n",
    "\n",
    "- 更好的未知稳健性：从上表4可以看出，在域外问题上，笔记链将拒绝率提高了+10.5。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "五、关键要点\n",
    "\n",
    "- 笔记链增强了RALM对噪声检索和未知场景的鲁棒性；\n",
    "\n",
    "- 记笔记为RALM推理过程提供了可解释性；\n",
    "\n",
    "- 平衡检索信息、进行推断和确认限制；\n",
    "\n",
    "- 分解复杂问题的简单而有效的方法。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
