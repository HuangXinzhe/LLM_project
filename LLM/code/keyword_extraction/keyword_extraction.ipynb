{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用KeyLLM和KeyBert进行关键词抽取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/UKPLab/sentence-transformers\n",
    "!pip install keybert ctransformers[cuda]\n",
    "!pip install --upgrade git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型\n",
    "加载模型并卸载模型50层到GPU，这样会减少RAM的使用，转而使用VRAM。如果遇到内存错误，可以继续减少此参数（gpu_layers）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. \n",
    "# Set to 0 if no GPU acceleration is available on your system.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "    model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",  # model_file表示模型文件的路径\n",
    "    model_type=\"mistral\",\n",
    "    gpu_layers=50,\n",
    "    hf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用sentence-transformers加载完模型之后，我们就可以继续使用transformers库来构建pipeline，包括tokenizer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "\n",
    "# Pipeline\n",
    "generator = pipeline(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    max_new_tokens=50,\n",
    "    repetition_penalty=1.1  # 该参数用于控制生成文本的多样性\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "I have the following document:\n",
    "* The website mentions that it only takes a couple of days to deliver but I still have not received mine\n",
    "\n",
    "Extract 5 keywords from that document.\n",
    "\"\"\"\n",
    "response = generator(prompt)\n",
    "print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 丰富提示词以获取更优质的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"\"\"\n",
    "<s>[INST]\n",
    "I have the following document:\n",
    "- The website mentions that it only takes a couple of days to deliver but I still have not received mine.\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST] meat, beef, eat, eating, emissions, steak, food, health, processed, chicken</s>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keyword_prompt = \"\"\"\n",
    "[INST]\n",
    "I have the following document:\n",
    "- [DOCUMENT]\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = example_prompt + keyword_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert.llm import TextGeneration\n",
    "from keybert import KeyLLM\n",
    "\n",
    "# Load it in KeyLLM\n",
    "llm = TextGeneration(generator, prompt=prompt)\n",
    "kw_model = KeyLLM(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "\"The website mentions that it only takes a couple of days to deliver but I still have not received mine.\",\n",
    "\"I received my package!\",\n",
    "\"Whereas the most powerful LLMs have generally been accessible only through limited APIs (if at all), Meta released LLaMA's model weights to the research community under a noncommercial license.\"\n",
    "]\n",
    "\n",
    "keywords = kw_model.extract_keywords(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更高效使用KeyLLM抽取关键词\n",
    "- 首先embedding所有文档，并将它们转换为数字表示；\n",
    "- 其次，找出哪些文档彼此最相似，假设高度相似的文档将具有相同的关键字，因此不需要为所有文档提取关键字。\n",
    "- 第三，只从每个聚类中的一个文档中提取关键字，并将关键字分配给同一聚类中的所有文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyLLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Extract embeddings\n",
    "model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
    "embeddings = model.encode(documents, convert_to_tensor=True)\n",
    "\n",
    "# Load it in KeyLLM\n",
    "kw_model = KeyLLM(llm)\n",
    "\n",
    "# Extract keywords\n",
    "keywords = kw_model.extract_keywords(\n",
    "    documents, \n",
    "    embeddings=embeddings, \n",
    "    threshold=.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold增加到大约.95将识别几乎相同的文档，而将其设置为大约.5将识别关于相同主题的文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述是通过embedding对文本相似度进行判断，下面是通过keybert对关键词的提取完成对文本相似度的判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyLLM, KeyBERT\n",
    "\n",
    "# Load it in KeyLLM\n",
    "kw_model = KeyBERT(llm=llm, model='BAAI/bge-small-en-v1.5')\n",
    "\n",
    "# Extract keywords\n",
    "keywords = kw_model.extract_keywords(documents, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
