# 重新思考大模型知识注入框架
- 本文研究了大型语言模型在垂直领域特定任务中如何更好地利用外部知识。通过注入随机的知识元组到LLMs中，可以得到与注入对齐知识相媲美的结果
- 作者提出了一种简单的改进技术，即强调对注入LLMs的外部知识库进行修剪和净化。通过将这种技术与大部分知识注入框架和最新的LLMs集成，成功解决了这个问题并推动了领域自适应LLMs性能的提升。

论文名称：Revisiting the Knowledge Injection Frameworks
论文地址：https://arxiv.org/abs/2311.01150.pdf

## 总结
本文介绍了一个关于知识注入框架的综合实证研究。通过一系列的测试和消融协议，我们发现大多数以前的知识注入方法都存在错误。我们提出了噪声注入的相似性解释，并提供了一个简单的修复方法来解决这些问题。我们鼓励学术界进一步检查知识注入方法，并更加关注知识本身，而不仅仅是注入机制或神经架构。最后，我们希望我们的协议能够在未来的研究中作为一个合理性检查的工具，并将我们的简单修复方法作为额外的基准应用。